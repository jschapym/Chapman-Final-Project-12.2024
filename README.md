# Chapman-Final-Project-12.2024
Investigating discrimination in AI-Resume Screening

This is the final project for my Master's in Data Science Program at Northwestern University. Research began in July 2024 and commenced in December 2024.
The Python file contains the code written for this project.
A k-Nearest-Neighbors analysis was run on a set of Resume data to determine how accurate a testing set could be in determining the job category of each resume. Gender and Ethnicity were then predicted using various packages and the applicants' first names. 
It was determined that there is a simple resolution to discrimination in resume screening: ceasing the use of historical hiring data when writing the algorithms that screen resumes.
My KNN analysis suggests that, if a simple job description with requirements for the position is fed through an algorithm and resumes are screened against this, discrimination in AI screening could be significantly reduced. 
When comparing the word choices of people of different genders and ethnicities, it is evident that there are distinctions among them. When historical hiring data is used, certain word choices and phrasing choices used by different demographics of individuals may be automatically screened out, disabling them from qualifying for a position they may otherwise be qualified for.
Suggestions:
-Feed a simple job description through the AI and base all resume screening off of that. 
-Be inclusive of word and phrase choices.
-Continuously monitor and audit AI screening devices to improve efficacy and efficiency.
-Recognize that these systems inherently come with risks because of the lack of human control, but can ultimately decrease implicit hiring biases.
I have also attached my final report for this project, detailing my methodology and results and conclusions based on this study. 
