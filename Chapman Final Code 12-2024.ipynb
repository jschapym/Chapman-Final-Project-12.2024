{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db325b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumedata = pd.read_csv('Resume Dataset including names.csv')\n",
    "print(resumedata.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76887c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#Preprocessing Textual Data\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "resumedata['Text'] = resumedata['Text'].apply(preprocess_text)\n",
    "\n",
    "print(resumedata[['Text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1987b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1500, stop_words='english')\n",
    "X = vectorizer.fit_transform(resumedata['Text'])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d249d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(resumedata['Category'])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c145823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Dataset into 80% training and 20% testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58907372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Nearest-Neighbors Classifier with 3 clusters\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(f'Accuracy on training set: {knn.score(X_train, y_train):.2f}')\n",
    "print(f'Accuracy on test set: {knn.score(X_test, y_test):.2f}')\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8238519",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "baby_names = pd.read_csv('baby-names.csv')\n",
    "\n",
    "#Processing the names and ensuring that none of the words that were previously selected (that were not names) are selected.\n",
    "baby_names_set = set(baby_names['name'].str.lower()) \n",
    "\n",
    "non_name_terms = {'texas', 'green', 'page', 'junior', 'senior', 'mr', 'ms', 'dr', 'first', 'last', 'place', 'may', 'angeles'}\n",
    "\n",
    "#Taking the first name from the dataset and only selecting the first valid name.\n",
    "def extract_first_valid_name_and_predict_gender(text, baby_names_set, non_name_terms):\n",
    "    normalized_text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
    "    words_in_text = normalized_text.split()\n",
    "    for word in words_in_text:\n",
    "        if word in baby_names_set and word not in non_name_terms:\n",
    "            predicted_gender = baby_names[baby_names['name'].str.lower() == word]['sex'].iloc[0]\n",
    "            return predicted_gender, word\n",
    "    return 'unknown', None\n",
    "\n",
    "#Adding prediction to the resumedata set\n",
    "def apply_gender_prediction(resumedata, baby_names_set, non_name_terms):\n",
    "    predicted_genders = []\n",
    "    extracted_names = []\n",
    "    \n",
    "    for text in resumedata['Text']:\n",
    "        predicted_gender, found_name = extract_first_valid_name_and_predict_gender(text, baby_names_set, non_name_terms)\n",
    "        predicted_genders.append(predicted_gender)\n",
    "        extracted_names.append(found_name)\n",
    "    resumedata['predicted_gender'] = predicted_genders\n",
    "    resumedata['extracted_names'] = extracted_names\n",
    "\n",
    "apply_gender_prediction(resumedata, baby_names_set, non_name_terms)\n",
    "\n",
    "print(resumedata[['Text', 'predicted_gender', 'extracted_names']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ethnicolr\n",
    "\n",
    "#Need a dummy column for last name in order for Ethnicolr to work\n",
    "resumedata['dummy_last_name'] = ''  \n",
    "\n",
    "#Run resumedata set through ethicolr to predict ethnicity\n",
    "resumedata = ethnicolr.pred_wiki_name(resumedata, fname_col='extracted_names', lname_col='dummy_last_name')\n",
    "\n",
    "print(resumedata.columns)\n",
    "\n",
    "ethnicity_columns = [col for col in resumedata.columns if \"GreaterEuropean\" in col or \"WestEuropean\" in col]  # Adjust this based on the actual columns\n",
    "\n",
    "resumedata['predicted_ethnicity'] = resumedata[ethnicity_columns].idxmax(axis=1)\n",
    "\n",
    "print(resumedata[['Text', 'extracted_names', 'predicted_gender', 'predicted_ethnicity']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b228550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking counts for gender and ethnicity\n",
    "gender_counts = resumedata['predicted_gender'].value_counts()\n",
    "ethnicity_counts = resumedata['predicted_ethnicity'].value_counts()\n",
    "\n",
    "print(\"Gender Distribution:\\n\", gender_counts)\n",
    "print(\"\\nEthnicity Distribution:\\n\", ethnicity_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Bar Chart showing the quantities of each ethnicity and gender in each job category\n",
    "ethnicity_mapping = {\n",
    "    0: 'GreaterEuropean,British',\n",
    "    1: 'GreaterEuropean,EastEuropean',\n",
    "    2: 'GreaterEuropean,Jewish',\n",
    "    3: 'GreaterEuropean,WestEuropean,French',\n",
    "    4: 'GreaterEuropean,WestEuropean,Germanic',\n",
    "    5: 'GreaterEuropean,WestEuropean,Hispanic',\n",
    "    6: 'GreaterEuropean,WestEuropean,Italian',\n",
    "    7: 'GreaterEuropean,WestEuropean,Nordic'\n",
    "}\n",
    "\n",
    "\n",
    "resumedata['ethnicity_label'] = resumedata['encoded_ethnicity'].map(ethnicity_mapping)\n",
    "\n",
    "#Plot distribution of ethnicities\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(data=resumedata, x='encoded_category', hue='ethnicity_label', palette='Set1')\n",
    "plt.title('Ethnicity Distribution in Each Job Category')\n",
    "plt.xlabel('Job Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Ethnicity', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Plot distribution of gender\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(data=resumedata, x='encoded_category', hue='predicted_gender', palette='Set2')\n",
    "plt.title('Gender Distribution in Each Job Category')\n",
    "plt.xlabel('Job Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Gender', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a9fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Heatmaps to detail the number of each ethnicity and gender per job category\n",
    "filtered_data_gender = resumedata[~resumedata['predicted_gender'].isin([None, 'unknown'])]\n",
    "filtered_data_ethnicity = resumedata[~resumedata['predicted_ethnicity'].isin([None, 'unknown'])]\n",
    "\n",
    "gender_counts = filtered_data_gender.groupby(['Category', 'predicted_gender']).size().reset_index(name='count')\n",
    "\n",
    "#Pivot Plot for gender and ethnicity distribution\n",
    "gender_pivot = gender_counts.pivot_table(index='Category', columns='predicted_gender', values='count', aggfunc='sum', fill_value=0)\n",
    "\n",
    "#Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(gender_pivot, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Number of Candidates'}, annot_kws={'size': 10})\n",
    "plt.title('Distribution of Job Categories by Predicted Gender (Excluding Null and Unknown)', fontsize=14)\n",
    "plt.xlabel('Predicted Gender', fontsize=12)\n",
    "plt.ylabel('Job Category', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ethnicity_counts = filtered_data_ethnicity.groupby(['Category', 'predicted_ethnicity']).size().reset_index(name='count')\n",
    "\n",
    "ethnicity_pivot = ethnicity_counts.pivot_table(index='Category', columns='predicted_ethnicity', values='count', aggfunc='sum', fill_value=0)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(ethnicity_pivot, annot=True, fmt='d', cmap='YlGnBu', cbar_kws={'label': 'Number of Candidates'}, annot_kws={'size': 10})\n",
    "plt.title('Distribution of Job Categories by Predicted Ethnicity (Excluding Null and Unknown)', fontsize=14)\n",
    "plt.xlabel('Predicted Ethnicity', fontsize=12)\n",
    "plt.ylabel('Job Category', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48223c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "#Creating Wordcloud to enhance specific words used by either gender\n",
    "\n",
    "#Filter through data of male and female candidates and plot Wordclouds\n",
    "male_data = resumedata[resumedata['predicted_gender'] == 'boy']\n",
    "female_data = resumedata[resumedata['predicted_gender'] == 'girl']\n",
    "\n",
    "male_text = \" \".join(male_data['Text'].dropna())\n",
    "female_text = \" \".join(female_data['Text'].dropna())\n",
    "\n",
    "male_wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(male_text)\n",
    "female_wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(female_text)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(male_wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud for Males\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(female_wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud for Females\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b153162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering data and listing the top 5 words for each gender \n",
    "if 'predicted_gender' not in resumedata.columns or 'Text' not in resumedata.columns:\n",
    "    print(\"Error: Required columns 'predicted_gender' or 'Text' are missing in the DataFrame.\")\n",
    "else:\n",
    "    male_data = resumedata[resumedata['predicted_gender'] == 'boy']\n",
    "    female_data = resumedata[resumedata['predicted_gender'] == 'girl']\n",
    "    male_text = \" \".join(male_data['Text'].dropna())\n",
    "    female_text = \" \".join(female_data['Text'].dropna())\n",
    "\n",
    "    male_word_counts = Counter(male_text)\n",
    "    female_word_counts = Counter(female_text)\n",
    "    \n",
    "    top_5_male = male_word_counts.most_common(5)\n",
    "    top_5_female = female_word_counts.most_common(5)\n",
    "    \n",
    "    print(\"Top 5 words for Males:\")\n",
    "    for word, count in top_5_male:\n",
    "        print(f\"{word}: {count}\")\n",
    "    \n",
    "    print(\"\\nTop 5 words for Females:\")\n",
    "    for word, count in top_5_female:\n",
    "        print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a352408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter through ethnicities and plot wordclouds for all\n",
    "if 'predicted_ethnicity' not in resumedata.columns:\n",
    "    print(\"Error: 'predicted_ethnicity' column not found in the DataFrame\")\n",
    "else:\n",
    "    ethnicities = resumedata['predicted_ethnicity'].unique()\n",
    "    num_ethnicities = len(ethnicities)\n",
    "    rows = int(np.ceil(num_ethnicities / cols)) \n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))\n",
    "    axes = axes.flatten() \n",
    "\n",
    "    for idx, ethnicity in enumerate(ethnicities):\n",
    "        ethnicity_data = resumedata[resumedata['predicted_ethnicity'] == ethnicity]\n",
    "        text_data = \" \".join(ethnicity_data['Text'].dropna())\n",
    "        \n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_data)\n",
    "        ax = axes[idx]\n",
    "        ax.imshow(wordcloud, interpolation='bilinear')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'WordCloud for {ethnicity}', fontsize=12)\n",
    "    for idx in range(num_ethnicities, len(axes)):\n",
    "        axes[idx].axis('off')  \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eacfc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering Ethnicity data to determine the top 5 words for each\n",
    "if 'predicted_ethnicity' not in resumedata.columns or 'Text' not in resumedata.columns:\n",
    "    print(\"Error: Required columns 'predicted_ethnicity' or 'Text' are missing in the DataFrame.\")\n",
    "else:\n",
    "    ethnicities = resumedata['predicted_ethnicity'].unique()\n",
    "\n",
    "    for ethnicity in ethnicities:\n",
    "        ethnicity_data = resumedata[resumedata['predicted_ethnicity'] == ethnicity]\n",
    "        \n",
    "        all_text = \" \".join(ethnicity_data['Text'].dropna())\n",
    "        \n",
    "        word_counts = Counter(all_text)\n",
    "\n",
    "        top_5_words = word_counts.most_common(5)\n",
    "\n",
    "        print(f\"Top 5 words for ethnicity '{ethnicity}':\")\n",
    "        for word, count in top_5_words:\n",
    "            print(f\"{word}: {count}\")\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
